## About

![Grand Exposition Setup](https://github.com/jrmedd/SonicPixels/blob/master/docs/setup_test.gif?raw=true)


We deployed this installation as part of the [Grand Exposition](http://agrandexposition.cornbrookcreative.uk/), for [Manchester Science Festival](http://www.manchestersciencefestival.com/), in October 2017. 25 speaker units were suspended from the ceiling, and play sounds according to the drawings that audience members created on the iPad.

This repo holds the [Micro:bit](http://microbit.org/) and [Max](https://cycling74.com) frameworks for triggering multiple speakers in a grid. The diagram below shows the flow of messages:

![SP control flow](https://github.com/jrmedd/SonicPixels/blob/master/docs/sonicPixelsComms.png?raw=true)

## Overview

_From the original pitch written up by [Cornbrook Creative](http://cornbrookcreative.uk/) and [Noise Orchestra](https://noiseorchestra.org/) for [Manchester Science Festival](http://www.manchestersciencefestival.com/):_

Imagine being a listener at the heart of a dynamic dawn chorus of bird song, the urban soundscape of Manchester City Centre, or the sounds of the Solar System as recorded by NASA’s Voyager missions.

What if these sonic experiences were created not through the conventional mediums of surround sound, ambisonics, complex signal processing and effects - but rather through a matrix of multiple remote-controlled mini speakers arranged in a regular grid - like pixels on a screen.

Like pixels on a screen, this bespoke audio delivery system would allow us to ‘draw’, ‘paint’ and ‘animate’ with sound - to create sonic equivalents of brightness, hue and dynamic texture - not via a carefully pre-arranged multichannel audio composition - but through remote, real-time, algorithmic manipulation of each speaker - each ‘sonic pixel’ - within the grid.
